<project_instructions version="1.3" xmlns="https://concatenator/spec">
    <!-- Canonical manifest that lists other project context files -->
    <context_index desc="Prefer this first if present AND signed by concatenator.">
        <filename>context_index.txt</filename>
        <required>preferred</required> <!-- required|preferred|optional -->
        <priority>100</priority>        <!-- higher = earlier -->
        <signature desc="Both markers MUST be present near the top of file.">
            <marker>// type: autogenerated</marker>
            <marker>// signature: concatenator</marker>
        </signature>
        <expectations desc="What we expect inside the signed index.">
            <contains_array name="files" desc="Paths to context/spec assets."></contains_array>
            <may_contain key="project"></may_contain>
            <may_contain key="generated_at"></may_contain>
        </expectations>
    </context_index>

    <!-- The human-facing project overview / README / to_do aggregator -->
    <spec desc="Always try to load this first (after validating index).">
        <filename>spec.txt</filename>
        <required>preferred</required>
        <priority>95</priority>
        <resolution_order desc="How to find spec.txt.">
            <step>1) If signed context_index lists a path ending with 'spec.txt', use that path.</step>
            <step>2) Otherwise, search supplied files for 'spec.txt' at repo root or documented locations.</step>
        </resolution_order>
        <role desc="Semantics">
            <statement>Canonical overview: goals, README excerpts, to_do lists, policy notes.</statement>
            <conflicts desc="When spec and other contexts disagree:">
                <rule>Spec governs human-facing priorities; index governs merge ordering.</rule>
            </conflicts>
        </role>
    </spec>

    <!-- Additional concatenated context blocks -->
    <contexts desc="Merge AFTER spec. Detect via header markers inside any file.">
        <glob>**/.concatenator/context/*.txt</glob>
        <priority>50</priority>
        <block_markers>
            <begin>---CONTEXT-HEADER-BEGIN---</begin>
            <end>---CONTEXT-HEADER-END---</end>
        </block_markers>
    </contexts>

    <!-- Legacy single-file context for backward compatibility only -->
    <legacy_context desc="Use ONLY as last resort for older projects.">
        <filename>context.txt</filename>
        <required>optional</required>
        <priority>10</priority>
        <when_to_use>
            <rule>Only if NO signed context_index AND NO spec.txt AND NO detectable context blocks exist.</rule>
        </when_to_use>
    </legacy_context>

    <!-- What to do if the index is missing or unsigned -->
    <fallback desc="Order of preference when no signed context_index is available.">
        <order>
            <step>Try spec.txt (repo root or standard locations).</step>
            <step>Then, scan for files containing context header blocks.</step>
            <step>Finally, if nothing else found, read legacy context.txt.</step>
        </order>
    </fallback>

    <!-- Add near <fallback>: partial-load strategy so big files don’t starve context -->
    <chunking_strategy desc="Load only what’s needed, but keep provenance.">
        <policy>header_guided</policy>
        <chunk_bytes>131072</chunk_bytes> <!-- 128 KiB per chunk -->
        <max_chunks>12</max_chunks>
        <selection>
            <rule>Score headers by TF-IDF or keyword overlap with the user question; include top-K.</rule>
            <rule>Always include spec sections: objectives|to_do|constraints.</rule>
        </selection>
    </chunking_strategy>

    <long_answer_policy desc="How to produce answers that would exceed output budgets.">
        <defaults>
            <mode>paginate</mode> <!-- paginate | summarize | outline_then_expand -->
            <max_pages>10</max_pages>
            <page_size_tokens>1500</page_size_tokens>
        </defaults>
        <when_needed desc="Trigger this if projected output > soft_output_tokens.">
            <negotiate_with_user>
                <prompt>“Response is larger than the budget. Prefer: (1) summary, (2) paginated parts, (3) approve bigger budget?”</prompt>
            </negotiate_with_user>
        </when_needed>
        <approval_required desc="Exceeding hard_output_tokens or hard_input_tokens requires approval.">
            <tool name="request_budget_approval" blocking="true">
                <inputs>
                    <field name="reason"></field>
                    <field name="projected_input_tokens"></field>
                    <field name="projected_output_tokens"></field>
                    <field name="alternatives" desc="summary|paginate|outline_then_expand"></field>
                    <field name="estimated_cost"></field>
                </inputs>
                <outputs>
                    <field name="decision" enum="approved|rejected|use_alternative"></field>
                    <field name="approved_input_tokens" optional="true"></field>
                    <field name="approved_output_tokens" optional="true"></field>
                </outputs>
            </tool>
        </approval_required>
    </long_answer_policy>

    <pagination_contract desc="Deterministic multi-part responses.">
        <page_header>
            <line>Page {n}/{N}</line>
            <line>context_index: {context_index_entry}</line>
            <line>filepath: {embedded_path}</line>
        </page_header>
        <continuation>
            <token name="continuation_token" desc="Opaque token the agent can echo to continue."></token>
            <request_line>“Reply ‘continue {continuation_token}’ for next page.”</request_line>
        </continuation>
    </pagination_contract>

    <!-- validation/linting so the XML and index aren’t silently drifting -->
    <validation desc="Fail fast on malformed inputs.">
        <xml_schema href="https://concatenator/spec/xsd/v1.xsd" optional="true"/>
        <index_checks>
            <rule>Each object must include concatenated_file AND output.</rule>
            <rule>generated_at must be ISO-8601 Zulu.</rule>
            <rule>output path must end with the same filename as concatenated_file.</rule>
            <rule>concatenated_file must be unique across objects.</rule>
            <rule>If duplicates exist, use the one with the latest generated_at; log a warning.</rule>
        </index_checks>
        <on_failure>abort_with_error_and_audit</on_failure>
    </validation>

    <!-- near <validation> -->
    <size_projection desc="Lightweight estimator to protect budgets.">
        <rules>
            <rule>If sum(selected_chunk_bytes) / 4 > {{token_budget.ref_names.soft_input}} → prefer paginate.</rule>
            <rule>If estimated_output_tokens > {{token_budget.ref_names.soft_output}} → switch to long_answer_policy.</rule>
            <rule>Stop before any {{token_budget.ref_names.hard_*}} thresholds and request approval.</rule>
        </rules>
    </size_projection>

    <!-- Add: explicit locale/timezone + absolute dates (you prefer Amsterdam) -->
    <temporal_policies>
        <timezone>Europe/Amsterdam</timezone>
        <format>ISO-8601</format>
        <require_absolute_dates>true</require_absolute_dates>
        <relative_date_rule>Convert 'today/tomorrow/yesterday' to absolute with timezone above.</relative_date_rule>
    </temporal_policies>

    <ci_hooks desc="Glue into PRs, checks, and deploy gates.">
        <on_open_pr>
            <action>attach_audit_trail_as_comment</action>
            <action>label_with_change_level</action>
        </on_open_pr>
        <required_checks>
            <check>unit_tests</check>
            <check>lint</check>
            <check>security_scan</check>
        </required_checks>
    </ci_hooks>

    <style_guide>
        <attributes>
            <rule>Use name="", desc="", required="", priority="" consistently.</rule>
            <rule>Booleans are lowercase: true|false.</rule>
            <rule>Enumerations use pipes: a|b|c.</rule>
        </attributes>
        <reserved_names>
            <name>INDEX_SIGNED</name>
            <name>files_used_in_order</name>
            <name>source_tracebacks</name>
        </reserved_names>
    </style_guide>

    <provenance desc="Record and emit precise source tracebacks for every used chunk.">
        <collect_when desc="Every time you read from any context chunk (spec, block, legacy).">
            <tuple_schema desc="Fields to capture for each chunk.">
                <field name="chunk_id" required="yes"
                       desc="Deterministic hash of {context_index_entry, embedded_path, line_range}."/>
                <field name="context_index_entry" required="yes"
                       desc="The filename as listed in context_index.txt (the concatenated artifact, e.g., 'apis.txt')."/>
                <field name="embedded_path" required="yes"
                       desc="The intra-concatenation source path referenced by that index/file header (e.g., '../entry-compiler/app.swift')."/>
                <field name="header_title" required="optional"
                       desc="If the header block exposes a subsection/title for the embedded_path, capture it (e.g., function or section name)."/>
                <field name="line_range" required="optional"
                       desc="Best-effort 1-based line span within the concatenation file that maps to the embedded_path content (e.g., '1243–1379')."/>
                <field name="evidence" required="optional"
                       desc="Raw header lines or key:value pairs that proved the mapping (store minimally)."/>
            </tuple_schema>

            <extraction_rules desc="How to find 'embedded_path' inside a concatenation header.">
                <rule>Prefer explicit keys inside the header block such as 'path', 'filepath', 'source', or 'file'.</rule>
                <rule>If multiple candidates exist, choose the first non-empty absolute/relative path-like value.</rule>
                <rule>If no explicit key exists, use the first line that looks like a path (contains '/' or ends with a known extension).</rule>
            </extraction_rules>
        </collect_when>

        <emit_as desc="Canonical, human-readable lines to include in all outputs and audits.">
            <line>chunk_id: {chunk_id}</line>
            <line>context_index: {context_index_entry}</line>
            <line>filepath: {embedded_path}</line>
            <line optional="yes">section: {header_title}</line>
            <line optional="yes">lines: {line_range}</line>
        </emit_as>

        <requirements desc="Where these MUST appear.">
            <location>At the top of any answer that cites project files.</location>
            <location>Inside the final audit report.</location>
            <location>Next to any quoted or summarized code/data snippet.</location>
        </requirements>
    </provenance>

    <privacy_and_secrets desc="Never leak sensitive data in answers or audits.">
        <redaction>
            <detect_patterns>
                <pattern>-----BEGIN [A-Z ]*PRIVATE KEY-----</pattern>
                <pattern>\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b</pattern>
                <pattern>bearer\s+[A-Za-z0-9\-_\.=]+</pattern>
            </detect_patterns>
            <action>mask</action>
            <mask>«redacted»</mask>
        </redaction>
        <secret_sources>
            <rule>Never read files flagged by protectSecrets=true unless allowSecrets explicitly set.</rule>
            <rule>Never print full contents of files matching secret patterns; summarize only.</rule>
        </secret_sources>
    </privacy_and_secrets>

    <!-- Enforcement rules the assistant MUST follow -->
    <enforcement desc="Deterministic procedure for loading and merging context.">
        <dry_run_policy desc="Default to simulation unless explicitly overridden.">
            <default>enabled</default>
            <override_requires>maintainer_approval</override_requires>
            <effects>
                <effect>generate_diffs_but_do_not_apply</effect>
                <effect>produce_rollback_plan</effect>
            </effects>
        </dry_run_policy>

        <!-- for near <operating_principles> or within <enforcement> -->
        <budget_negotiation desc="Mandatory steps before exceeding budgets.">
            <steps>
                <step>Estimate input/output tokens using chunk headers + page counts.</step>
                <step>Compare estimates to soft/hard budgets.</step>
                <step>If exceeding SOFT only → propose paginate/summary/outline_then_expand and proceed with user choice.</step>
                <step>If exceeding HARD → call request_budget_approval; pause until decision.</step>
                <step>Record decision in audit trail with approved numbers.</step>
            </steps>
            <fallbacks>
                <fallback>Produce high-fidelity summary with section pointers and provenance if approval is denied.</fallback>
                <fallback>Offer export-ready outline that the user can select sections from for deeper expansion.</fallback>
            </fallbacks>
        </budget_negotiation>

        <check_signed_index desc="Validate index authenticity.">
            <inspect_first_lines>40</inspect_first_lines>
            <must_contain>// type: autogenerated</must_contain>
            <must_contain>// signature: concatenator</must_contain>
            <result name="INDEX_SIGNED">true|false</result>
        </check_signed_index>

        <load_sequence desc="Strict processing order.">
            <step>1) If INDEX_SIGNED = true: accept context_index as authoritative manifest.</step>
            <step>2) Resolve and load spec.txt FIRST (prefer the path listed inside the index; else discover).</step>
            <step>3) Load concatenator-produced context blocks (by header markers).</step>
            <step>4) Load legacy context.txt ONLY as fallback.</step>
        </load_sequence>

        <conflict_resolution desc="How to merge overlapping keys/sections.">
            <rule>When INDEX_SIGNED = true, the manifest (index) controls merge order.</rule>
            <rule>Spec (spec.txt) governs human-facing priorities (overview, to_do, policies) but does not override index ordering.</rule>
            <rule>Per-file context blocks merge next.</rule>
            <rule>Legacy context.txt is lowest priority.</rule>
        </conflict_resolution>

        <audit_report desc="Always emit a short summary for traceability.">
            <include>index_signed</include>
            <include>files_used_in_order</include>
            <include>missing_expected_files</include>
            <include>warnings</include>
            <include>source_tracebacks</include> 
        </audit_report>
    </enforcement>

    <!-- Operational parameters -->
    <metadata>
        <preferred_encoding>utf-8</preferred_encoding>
        <max_header_lines_to_inspect>40</max_header_lines_to_inspect>
        <signed_context_preferred>true</signed_context_preferred>
    </metadata>

    <!-- Put this near <metadata> -->
    <runtime_limits desc="Token, time, and size budgets with explicit escalation.">
        <token_budget>
            <ref_names>
                <soft_input>soft_input_tokens</soft_input>
                <hard_input>hard_input_tokens</hard_input>
                <soft_output>soft_output_tokens</soft_output>
                <hard_output>hard_output_tokens</hard_output>
            </ref_names>
            <soft_input_tokens>80000</soft_input_tokens>
            <hard_input_tokens>120000</hard_input_tokens>
            <soft_output_tokens>2000</soft_output_tokens>
            <hard_output_tokens>4000</hard_output_tokens>
            <exceed_policy desc="What to do when a soft/hard limit would be exceeded.">
                <on_soft_exceed>negotiate_or_paginate</on_soft_exceed>
                <on_hard_exceed>block_and_request_approval</on_hard_exceed>
            </exceed_policy>
        </token_budget>
        <timeouts>
            <tool_call_ms>45000</tool_call_ms>
            <overall_run_ms>300000</overall_run_ms>
            <on_timeout>abort_with_audit</on_timeout>
        </timeouts>
        <file_caps>
            <max_supplied_files>200</max_supplied_files>
            <max_file_bytes>5242880</max_file_bytes> <!-- 5 MiB per file -->
            <oversize_policy>skip_and_audit</oversize_policy>
        </file_caps>
    </runtime_limits>

    <!-- Example: minimal accepted index layout (for tool authors) -->
    <example_index desc="Illustrative payload within context_index.txt">
        <preamble>// type: autogenerated</preamble>
        <preamble>// signature: concatenator</preamble>
        <body>
            <![CDATA[
                {
                  "title" : "server production live APIs",
                  "details" : "Contains the monorepo of all APIs running on two production live servers.\n\nNodeJS APIs are running on api-pie.\n\nSwift APIs are running on malinois.",
                  "dependencies" : [
                    "varies_per_implementation"
                  ],
                  "concatenated_file" : "apis.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/apis.txt",
                  "generated_at" : "2025-09-20T12:42:09Z"
                }

                {
                  "title" : "One of the production APIs",
                  "details" : "A subrepo of apis.txt, with narrowed scope\n\nHandles forwarding to other APIs, such as google, apple, pdok, etc.",
                  "concatenated_file" : "forwarder_v1.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/forwarder_v1.txt",
                  "generated_at" : "2025-09-20T12:42:09Z"
                }

                {
                  "title" : "Interfaces swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nInterfaces stands for application programming interfaces.\nThat is: here we implement various smaller APIs, either for local use, or that can be taken up by other libraries.\n\nIt is the brain of what we can invoke in implementations elsewhere.",
                  "dependencies" : [
                    "plate",
                    "Structures",
                    "Extensions"
                  ],
                  "concatenated_file" : "lib_interfaces.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_interfaces.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }

                {
                  "title" : "Surfaces swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nSurfaces stands for 'MicroSurfaces', as in: exposed touch points for API implementations.\nIt uses my other libraries like plate, Interfaces, Structures, Extensions, and Commerce.\n\nIt is meant to be our prepatory codebase before we start integrating it with Vapor.\n\nIt is therefore the setup for our Vaporized library, which pairs the contents of Surfaces to Vapor and related frameworks.\n\nNotably therefore, Vaporized depends on Surfaces.",
                  "dependencies" : [
                    "plate",
                    "Structures",
                    "Extensions",
                    "Interfaces",
                    "Commerce"
                  ],
                  "concatenated_file" : "lib_surfaces.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_surfaces.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }

                {
                  "title" : "Vaporized swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nVaporized stands for adding the Vapor (and any related) framework to the Surfaces library.\n\nIt is meant as our final exposure layer of implementing the core of our APIs in Swift.\n\nVaporized depends on Surfaces, which depends on our other libraries.\n\nVaporized therefore contains many of our other libraries as dependencies.",
                  "dependencies" : [
                    "plate",
                    "Structures",
                    "Extensions",
                    "Interfaces",
                    "Surfaces",
                    "Vapor",
                    "Fluent",
                    "FluentPostgresDriver",
                    "NIOCore",
                    "NIOPosix",
                    "JWTKit"
                  ],
                  "concatenated_file" : "lib_vaporized.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_vaporized.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }

                {
                  "title" : "ViewComponents swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nViewComponents is our way of creating reusable elements for UI.\n\nIt is mainly to be used by Compositions, or directly by front-end applications.\n\nIt makes heavy use of SwiftUI components and features, but wraps them to predesigned templates.\n\nIt can also invoke logic from plate, and models from Structures.",
                  "dependencies" : [
                    "plate",
                    "Structures"
                  ],
                  "concatenated_file" : "lib_viewcomponents.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_viewcomponents.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }

                {
                  "title" : "Implementations swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nImplementations is for implementing any logic and models and preparing it for front-end use.\n\nIt is the prepatory layer for Compositions, providing predominantly a lot viewmodels.\n\nIt is the brain aggregation layer for the views in Compositions and further front-end.",
                  "dependencies" : [
                    "plate",
                    "Structures",
                    "Interfaces",
                    "Economics",
                    "Commerce"
                  ],
                  "concatenated_file" : "lib_implementations.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_implementations.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }

                {
                  "title" : "Compositions swift library",
                  "details" : "Library that I created and maintain, written in Swift.\n\nCompositions is for creating unified views for final front-facing applications.\n\nIt makes heavy use of our ViewComponents library, as well as pairing it with Implementations.",
                  "dependencies" : [
                    "plate",
                    "ViewComponents",
                    "Interfaces",
                    "Economics",
                    "Implementations",
                    "Structures",
                    "Extensions"
                  ],
                  "concatenated_file" : "lib_compositions.txt",
                  "output" : "/Users/leviouwendijk/myworkdir/programming/specifications/spec.vaporized-microsurfaces/context/lib_compositions.txt",
                  "generated_at" : "2025-09-20T12:42:10Z"
                }
            ]]>
        </body>
    </example_index>

    <!-- Optional: a compact machine-parsable block you can append after the human lines -->
    <traceback_format desc="Recommended JSON line for logs; keep 1 line per chunk.">
        <![CDATA[
        {"context_index_entry":"apis.txt","embedded_path":"../entry-compiler/app.swift","header_title":"EntryCompileDriver","line_range":"1243-1379"}
        ]]>
    </traceback_format>

    <!-- Example rendering that matches your requested style -->
    <traceback_example desc="Human-facing lines to print alongside answers.">
        <line>context_index: apis.txt</line>
        <line>filepath: ../my-project-root/entry-point/app.swift</line>
    </traceback_example>

    <operating_principles>
        <!-- Core principles adapted from 12-Factor Agents -->
        <principles desc="High-level guardrails for agent behavior">
            <p key="nl_to_tools">Translate natural language into explicit tool calls with typed outputs; no hidden side-effects.</p>
            <p key="own_prompts">Own prompts and schemas; validate structured outputs before acting.</p>
            <p key="own_context">Curate the context window; include compact error traces and prior decisions.</p>
            <p key="unify_state">Persist execution state alongside business state for idempotent retries/replays.</p>
            <p key="lpr_api">Expose launch/pause/resume endpoints so runs can be safely halted for review.</p>
            <p key="humans_as_tools">Route high-stakes steps to humans via dedicated tool calls; block until approved.</p>
            <p key="own_control_flow">Keep control flow in normal code/workflows; avoid nesting opaque prompt loops.</p>
            <p key="errors_compact">Summarize errors into next-step context to self-heal.</p>
            <p key="small_agents">Prefer small, focused agents with clear responsibilities.</p>
            <p key="stateless_reducer">Default to a stateless reducer interface; derive outputs only from inputs + state.</p>
        </principles>

        <!-- Approval ladder: who must sign off, and when -->
        <approval_matrix desc="Degrees of change → degrees of approval; agent must enforce before applying changes.">
            <!-- 0: Purely conversational / info-gathering -->
            <change_level name="talk_requirements" risk="none">
                <examples>requirements Q&A; scoping; planning checklists</examples>
                <allowed_actions>unrestricted</allowed_actions>
                <human_approval>not_required</human_approval>
            </change_level>

            <!-- 1: Read-only and diagnostics -->
            <change_level name="read_only_analysis" risk="low">
                <examples>code search; log analysis; test plan proposal; RFC draft</examples>
                <allowed_actions>read_only</allowed_actions>
                <human_approval>not_required</human_approval>
            </change_level>

            <!-- 2: Trivial non-prod edits -->
            <change_level name="low_risk_write" risk="low">
                <examples>typo/docs; comment-only diffs; dev-only config; non-prod CI text</examples>
                <allowed_actions>open_PR</allowed_actions>
                <gates>
                    <gate>1_human_ack</gate>
                    <gate>auto_checks_pass</gate>
                </gates>
            </change_level>

            <!-- 3: Bug fix with tests -->
            <change_level name="bugfix_scoped" risk="moderate">
                <examples>contained fix with unit tests; non-breaking refactor in single module</examples>
                <allowed_actions>open_PR; propose_release_note</allowed_actions>
                <gates>
                    <gate>reviewers>=1</gate>
                    <gate>ci_green</gate>
                    <gate>staged_deploy_or_flag</gate>
                </gates>
            </change_level>

            <!-- 4: Cross-module refactor / data-touching migrations (non-breaking API) -->
            <change_level name="refactor_cross_module" risk="high">
                <examples>multi-package refactor; non-breaking DB migration; infra-as-code change</examples>
                <allowed_actions>draft_RFC; open_PR; create_change_plan</allowed_actions>
                <gates>
                    <gate>reviewers>=2</gate>
                    <gate>maintainer_approval</gate>
                    <gate>change_window</gate>
                    <gate>rollback_plan</gate>
                    <gate>can_pause_resume_run</gate>
                </gates>
            </change_level>

            <!-- 5: Breaking change / rewrite / schema break / prod data mutation -->
            <change_level name="breaking_or_rewrite" risk="critical">
                <examples>public API break; schema change with data backfill; rewrite; high-cost external calls</examples>
                <allowed_actions>draft_RFC; security_review; open_PR_locked</allowed_actions>
                <gates>
                    <gate>tech_lead_signoff</gate>
                    <gate>product_owner_signoff</gate>
                    <gate>security_or_data_owner_signoff</gate>
                    <gate>dry_run_and_metrics</gate>
                    <gate>feature_flag_rollout</gate>
                    <gate>manual_release_authorization</gate>
                </gates>
            </change_level>

            <!-- 6: Secrets / credentials / auth scopes -->
            <change_level name="secrets_and_access" risk="critical">
                <examples>creating/rotating credentials; widening auth scopes; touching KMS/secret stores</examples>
                <allowed_actions>propose_only</allowed_actions>
                <gates>
                    <gate>never_execute_autonomously</gate>
                    <gate>security_officer_approval</gate>
                    <gate>four_eyes_rule</gate>
                </gates>
            </change_level>
        </approval_matrix>

        <!-- How approvals are executed (Factor 6 + 7) -->
        <approval_execution desc="Approvals are first-class tools; runs must pause for decision.">
            <tool name="request_human_approval" blocking="true">
                <inputs>
                    <field>change_level</field>
                    <field>diff_or_plan_url</field>
                    <field>risk_summary</field>
                    <field>rollback_plan</field>
                    <field>blast_radius</field>
                    <field>cost_estimate</field>
                </inputs>
                <outputs>
                    <field name="decision" enum="approved|rejected|revise|timeboxed_experiment"></field>
                </outputs>
                <pause_resume>on_call → pause_run; on_decision → resume_or_abort</pause_resume>
            </tool>
            <persistence>
                <rule>Persist approval artifacts with execution state for replay/idempotence.</rule>
            </persistence>
        </approval_execution>

        <deployment_targets desc="Prevent accidental prod hits.">
            <target name="dev" default="true" risk="low"/>
            <target name="staging" risk="moderate"/>
            <target name="prod" risk="critical"/>
            <rules>
                <rule>prod requires change_level ≥ bugfix_scoped AND reviewers≥2 AND manual_release_authorization</rule>
                <rule>schema_migrations allowed only staging→prod with successful dry_run_and_metrics</rule>
            </rules>
        </deployment_targets>

        <!-- Guardrails the agent must check before taking write actions -->
        <preconditions desc="All must pass before any write or deployment.">
            <check>INDEX_SIGNED or explicit override by human</check>
            <check>spec.txt loaded first to align with project objectives</check>
            <check>tests_exist OR explicit waiver on low-risk levels</check>
            <check>ci_green for levels ≥ bugfix_scoped</check>
            <check>required_approvals_obtained per approval_matrix</check>
        </preconditions>

        <!-- What to log and surface back to the user (auditability) -->
        <audit_trail desc="Emit a human line and a machine line per action.">
            <human_lines>
                <line>context_index: {context_index_entry}</line>
                <line>filepath: {embedded_path}</line>
                <line optional="yes">section: {header_title}</line>
                <line optional="yes">approval: {decision} by {approver_ids} at {timestamp}</line>
            </human_lines>
            <machine_json>
                <![CDATA[
                    {"context_index_entry":"apis.txt","embedded_path":"../entry-compiler/app.swift","decision":"approved","approver_ids":["@maintainer","@security"],"timestamp":"2025-09-20T12:55:00Z"}
                ]]>
            </machine_json>
        </audit_trail>

        <audit_trail_extensions desc="Budget/continuation fields">
            <include>answer_mode</include>
            <include>pages_emitted</include>
            <include>projected_input_tokens</include>
            <include>projected_output_tokens</include>
            <include>budget_decision</include>
            <include>approved_input_tokens</include>
            <include>approved_output_tokens</include>
            <include>continuation_token</include>
        </audit_trail_extensions>
    </operating_principles>

    <!-- Final readiness gate for downstream tools -->
    <final_checklist desc="Set all to yes before consuming.">
        <index_present_and_signed></index_present_and_signed>
        <spec_located_and_loaded_first></spec_located_and_loaded_first>
        <merge_order_followed></merge_order_followed>
        <legacy_used_only_as_fallback></legacy_used_only_as_fallback>
        <audit_emitted></audit_emitted>
    </final_checklist>

    <conformance_test desc="Smoke-test an agent before using it on real work.">
        <given>
            <file>context_index.txt</file>
            <file>spec.txt</file>
            <file>.concatenator/context/overview.txt</file>
        </given>
        <ask>Summarize project goals and list the order you loaded sources.</ask>
        <expect>
            <contains>context_index: …</contains>
            <contains>filepath: …/spec.txt</contains>
            <contains>files_used_in_order</contains>
            <predicate>first_source == 'context_index.txt'</predicate>
            <predicate>second_source endswith 'spec.txt'</predicate>
        </expect>
    </conformance_test>
</project_instructions>
